{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n       # print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-03-13T07:41:41.090938Z","iopub.execute_input":"2023-03-13T07:41:41.091409Z","iopub.status.idle":"2023-03-13T07:41:41.100440Z","shell.execute_reply.started":"2023-03-13T07:41:41.091375Z","shell.execute_reply":"2023-03-13T07:41:41.098848Z"},"trusted":true},"execution_count":3,"outputs":[{"traceback":["\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_27/3621376407.py\"\u001b[0;36m, line \u001b[0;32m17\u001b[0m\n\u001b[0;31m    # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\u001b[0m\n\u001b[0m                                                                                                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"],"ename":"SyntaxError","evalue":"unexpected EOF while parsing (3621376407.py, line 17)","output_type":"error"}]},{"cell_type":"code","source":"import numpy as np\n\nfrom keras.preprocessing.image import image\n\nfrom keras.preprocessing.image import img_to_array\n\nfrom keras.applications.resnet50 import preprocess_input\n\nfrom keras.applications.imagenet_utils import decode_predictions\n\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2023-03-13T07:41:41.253164Z","iopub.execute_input":"2023-03-13T07:41:41.253663Z","iopub.status.idle":"2023-03-13T07:41:48.762120Z","shell.execute_reply.started":"2023-03-13T07:41:41.253609Z","shell.execute_reply":"2023-03-13T07:41:48.759746Z"},"trusted":true},"execution_count":4,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/1012172650.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet50\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpreprocess_input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimagenet_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdecode_predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras.applications.resnet50'"],"ename":"ModuleNotFoundError","evalue":"No module named 'keras.applications.resnet50'","output_type":"error"}]},{"cell_type":"code","source":"img = image.load_img(/kaggle/input/btpdataset/val2017/val2017/2017_10024630.jpg’, target_size = (224, 224))\n\nplt.imshow(img)\n\nimg = image.img_to_array(img)\n\nimg = np.expand_dims(img, axis=0)\n\nimg = preprocess_input(img)","metadata":{"execution":{"iopub.status.busy":"2023-03-13T07:41:48.763177Z","iopub.status.idle":"2023-03-13T07:41:48.763640Z","shell.execute_reply.started":"2023-03-13T07:41:48.763428Z","shell.execute_reply":"2023-03-13T07:41:48.763449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = ResNet50(weights=’imagenet’)\n\npreds = model.predict(img)\n\nprint(‘Predicted:’, decode_predictions(preds, top=1)[0])\n","metadata":{"execution":{"iopub.status.busy":"2023-03-13T07:41:48.765185Z","iopub.status.idle":"2023-03-13T07:41:48.765874Z","shell.execute_reply.started":"2023-03-13T07:41:48.765519Z","shell.execute_reply":"2023-03-13T07:41:48.765556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install caffe\n","metadata":{"execution":{"iopub.status.busy":"2023-03-13T07:41:48.767748Z","iopub.status.idle":"2023-03-13T07:41:48.768168Z","shell.execute_reply.started":"2023-03-13T07:41:48.767972Z","shell.execute_reply":"2023-03-13T07:41:48.767991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# imports\nimport json\nimport time\nimport pickle\nimport scipy.misc\nimport skimage.io\nimport os\nimport sys\nimport csv\nimport copy\nfrom collections import Counter\n\nimport numpy as np\nimport os.path as osp\n\nimport json\nfrom random import shuffle\nfrom threading import Thread\nfrom PIL import Image\nfrom scipy.misc import imread\n\nCAFFE_ROOT = '/BS/orekondy/work/opt/caffe-wloss/'\nsys.path.insert(0, os.path.join(CAFFE_ROOT, 'python'))\nimport caffe\n\nsys.path.insert(1, CAFFE_ROOT + 'examples/pycaffe/layers')   # the datalayers we will use are in this directory.\nsys.path.insert(1, CAFFE_ROOT + 'examples/pycaffe')   # the tools file is in this folder\nfrom tools import SimpleTransformer\n\nATTRIBUTE_PATH = '/home/orekondy/work/blur_personal/multi_label_anno_tool/static/attributes_v2.tsv'\nSURVEY_RES_PATH = '/home/orekondy/work2/blur_personal/survey_graphs/survey_v5_res50.tsv'\nNUM_LABELS = 104\n\nSAFE_ATTR_ID = 'a0_safe'\nSAFE_WEIGHT = 0.0\n\n\ndef load_attributes(attribute_path=ATTRIBUTE_PATH):\n    attr_id_to_categ_id = dict()\n    attr_id_to_name = dict()\n    attr_id_to_mode = dict()\n    categ_id_to_name = dict()\n    attr_id_to_weight = dict()\n\n    with open(attribute_path, 'r') as fin:\n        ts = csv.DictReader(fin, delimiter='\\t')\n        rows = filter(lambda r: r['category_id'] is not '', [row for row in ts])\n\n        for row in rows:\n            attr_id_to_categ_id[row['attribute_id']] = row['category_id']\n            attr_id_to_name[row['attribute_id']] = row['attribute_name']\n            attr_id_to_mode[row['attribute_id']] = row['mode']\n            categ_id_to_name[row['category_id']] = row['category_name']\n            attr_id_to_weight[row['attribute_id']] = row['weight']\n\n    if os.path.exists(SURVEY_RES_PATH):\n        attr_id_to_weight = survey_to_weights(SURVEY_RES_PATH, use_attr=set(attr_id_to_name.keys()))\n\n    # Handle 'safe' label\n    attr_id_to_weight[SAFE_ATTR_ID] = SAFE_WEIGHT\n    attr_id_to_mode[SAFE_ATTR_ID] = 'visual'\n    attr_id_to_name[SAFE_ATTR_ID] = 'safe'\n\n    return attr_id_to_categ_id, attr_id_to_name, attr_id_to_mode, categ_id_to_name, attr_id_to_weight\n\n\ndef survey_to_weights(survey_res_path=SURVEY_RES_PATH, use_attr=None):\n    attr_id_to_weight = dict()\n\n    with open(survey_res_path, 'r') as fin:\n        ts = csv.DictReader(fin, delimiter='\\t')\n        rows = [row for row in ts]\n\n        for row in rows:\n            attr_id = row['attribute_id']\n\n            if use_attr is not None and attr_id not in use_attr:\n                # There might be some control attribute_ids. So, skip these.\n                continue\n\n            survey_res = [float(row[v]) for v in ('1', '2', '3', '4', '5')]\n            weighted_avg = sum([v1*v2 for (v1, v2) in zip([1, 2, 3, 4, 5], survey_res)]) / 30.0\n\n            attr_id_to_weight[attr_id] = weighted_avg\n\n    return attr_id_to_weight\n\n\ndef get_filename(filepath, drop_ext=False):\n    _, filename_with_ext = os.path.split(filepath)\n    if not drop_ext:\n        return filename_with_ext\n    else:\n        filename_without_ext, _ = os.path.splitext(filename_with_ext)\n        return filename_without_ext\n\n\ndef load_attr_to_idx():\n    attr_id_to_categ_id, attr_id_to_name, attr_id_to_mode, categ_id_to_name, attr_id_to_weight = load_attributes()\n    # Attributes are stored as \"aNN_name\". Sort using NN\n    attr_list = sorted(attr_id_to_name.keys(), key=lambda x: int(x.split('_')[0][1:]))\n    # attr_list = ['safe', ] + attr_list   # Treat 'safe' as another class\n\n    attr_id_to_idx = dict()\n    for idx, attr_id in enumerate(attr_list):\n        attr_id_to_idx[attr_id] = idx\n\n    return attr_id_to_idx\n\n\ndef attribute_set_to_vec(attr_id_to_idx, attr_set, is_safe):\n    num_labels = len(attr_id_to_idx)\n    label_vec = np.zeros(num_labels, dtype=np.float32)\n    for attr_id in attr_set:\n        if attr_id in attr_id_to_idx:\n            idx = attr_id_to_idx[attr_id]\n            label_vec[idx] = 1\n    if len(attr_set) == 0:\n        assert is_safe\n        idx = attr_id_to_idx[SAFE_ATTR_ID]\n        label_vec[idx] = 1\n    return label_vec\n\n\ndef get_w2idx(dictlist, attr_id_to_weight):\n    \"\"\"\n    1. Create a mapping of weight (int) -> attribute_idx\n       weight of example = max(weight of attribute i in example)\n    2. When sampling next image:\n      a. Sample weight ~ [1, 2, 3, 4, 5]\n      b. Sample an example corresponding to this weight\n    Maintain a dict:\n        {\n            1: [3, 10, 4, ...],\n            2: [45, 11, 90, ...],\n            ...\n        }\n    and pop an idx from the list when asked for next image\n    \"\"\"\n    weight_to_idx_list = {}\n\n    for idx, this_anno in enumerate(dictlist):\n        if 'labels' in this_anno:\n            this_attr_list = this_anno['labels']\n        else:\n            this_attr_list = []\n            for categ_id, attr_id_list in this_anno['attributes'].iteritems():\n                this_attr_list += attr_id_list\n        attr_id_set = set(this_attr_list)\n        # What's the weight of this training example?\n        if len(attr_id_set) == 0:\n            idx_weight = 1\n        else:\n            idx_weight = max([attr_id_to_weight.get(x, 1) for x in attr_id_set])\n        # This is a float. Cast it to int by rounding off.\n        idx_weight = int(np.round(idx_weight))\n        if idx_weight not in weight_to_idx_list:\n            weight_to_idx_list[idx_weight] = [idx, ]\n        else:\n            weight_to_idx_list[idx_weight].append(idx)\n\n    for w in sorted(weight_to_idx_list.keys()):\n        shuffle(weight_to_idx_list[w])\n        print '{} -> {}'.format(w, len(weight_to_idx_list[w]))\n\n    return weight_to_idx_list\n\n\ndef get_class2idx(dictlist):\n    \"\"\"\n    1. Create a mapping of LABEL (attr_id) -> DICT_IDX\n    2. When sampling next image:\n      a. Sample class ~ [attr_1, attr_2, ..., attr_L]\n      b. Sample an example corresponding to this label\n    Maintain a dict:\n        {\n            attr_1: [3, 10, 4, ...],\n            attr_2: [45, 11, 90, ...],\n            ...\n        }\n    and pop an idx from the list when asked for next image\n    \"\"\"\n    class_to_idx_list = {}\n\n    for idx, this_anno in enumerate(dictlist):\n        if 'labels' in this_anno:\n            this_attr_list = this_anno['labels']\n        else:\n            this_attr_list = []\n            for categ_id, attr_id_list in this_anno['attributes'].iteritems():\n                this_attr_list += attr_id_list\n        attr_id_set = set(this_attr_list)\n\n        for attr_id in attr_id_set:\n            if attr_id not in class_to_idx_list:\n                class_to_idx_list[attr_id] = [idx, ]\n            else:\n                class_to_idx_list[attr_id].append(idx)\n\n    for attr_id in sorted(class_to_idx_list.keys(), key=lambda x: x.split('_')[0][1:]):\n        shuffle(class_to_idx_list[attr_id])\n        print '{} -> {}'.format(attr_id, len(class_to_idx_list[attr_id]))\n\n    return class_to_idx_list\n\n\nclass PAPMultilabelDataLayerSync(caffe.Layer):\n\n    \"\"\"\n    This is a simple synchronous datalayer for training a multilabel model on\n    PASCAL.\n    \"\"\"\n\n    def setup(self, bottom, top):\n\n        self.top_names = ['data', 'label']\n\n        # === Read input parameters ===\n\n        # params is a python dictionary with layer parameters.\n        # Example param_str: param_str:\n        # \"{\\'anno_list\\': \\'/BS/orekondy2/work/blur_personal/experiments/8k/train_6k.txt\\', \\'im_shape\\': [227, 227], \\'batch_size\\': 128}\"\n        params = eval(self.param_str)\n\n        # Check the parameters for validity.\n        check_params(params)\n\n        # store input as class variables\n        self.batch_size = params['batch_size']\n\n        self.num_labels = params.get('nlabels', NUM_LABELS)\n\n        # Create a batch loader to load the images.\n        self.batch_loader = BatchLoader(params, None)\n\n        # Weighted loss\n        self.wloss = bool(params.get('wloss', 0))\n\n        # Return user preferences\n        self.user_prefs = params.get('user_prefs', None)\n        self.n_users = 0\n\n        self.pool = params.get('pool', 'max')\n        assert self.pool in ['sum', 'max', 'avg']\n\n        # === reshape tops ===\n        # since we use a fixed input image size, we can shape the data layer\n        # once. Else, we'd have to do it in the reshape call.\n        top[0].reshape(\n            self.batch_size, 3, params['im_shape'][0], params['im_shape'][1])\n        # Note the 20 channels (because PASCAL has 20 classes.)\n        top[1].reshape(self.batch_size, 68)\n\n        if self.wloss or len(top) > 2:\n            top[2].reshape(68)\n\n        if self.user_prefs is not None:\n            self.user_pref_mat = self.batch_loader.get_user_prefs()\n            n_attr, self.n_users = self.user_pref_mat.shape\n            print 'self.n_users = ', self.n_users\n            top[3].reshape(self.batch_size, self.n_users)\n\n        print_info(\"PAPMultilabelDataLayerSync\", params)\n\n    def forward(self, bottom, top):\n        \"\"\"\n        Load data.\n        \"\"\"\n\n        # print '******** top[0].shape = ', top[0].shape\n        # print '******** top[1].shape = ', top[1].shape\n\n        # Create a matrix N x A: Labels for each image\n        # This *may* be needed later on depending on whether user preferences are specified\n        n_attr = len(self.batch_loader.get_attr_id_list())\n        img_attr_mat = np.zeros((self.batch_size, n_attr))\n\n        for itt in range(self.batch_size):\n            # Use the batch loader to load the next image.\n            im, multilabel = self.batch_loader.load_next_image()\n\n            assert multilabel.shape[0] == n_attr\n            img_attr_mat[itt] = multilabel[:]\n\n            # Add directly to the caffe data layer\n            top[0].data[itt, ...] = im\n            top[1].data[itt, ...] = multilabel\n\n        if self.wloss:\n            top[2].data[...] = self.batch_loader.get_weights()\n\n        if self.user_prefs is not None:\n            '''\n            top[3] needs to be a matrix, say X, of dims batch_size x n_users\n            s.t. X[i, j] = Privacy score of image i for user j\n            '''\n            if self.pool in ['sum', 'avg']:\n                user_scores_mat = np.dot(img_attr_mat, self.user_pref_mat)\n                if self.pool == 'avg':\n                    # Get a N-dim vector representing #attributes in each example\n                    y_card_vec = np.sum(img_attr_mat, axis=1)\n                    user_scores_mat /= y_card_vec[:, None]\n            else:\n                user_scores_mat = np.zeros((self.batch_size, self.n_users))\n                for n in range(self.batch_size):\n                    for u in range(self.n_users):\n                        user_scores_mat[n, u] = np.max(img_attr_mat[n, :] * self.user_pref_mat[:, u])\n            top[3].data[...] = user_scores_mat\n\n    def reshape(self, bottom, top):\n        \"\"\"\n        There is no need to reshape the data, since the input is of fixed size\n        (rows and columns)\n        \"\"\"\n        pass\n\n    def backward(self, top, propagate_down, bottom):\n        \"\"\"\n        These layers does not back propagate\n        \"\"\"\n        pass\n\n\nclass BatchLoader(object):\n\n    \"\"\"\n    This class abstracts away the loading of images.\n    Images can either be loaded singly, or in a batch. The latter is used for\n    the asyncronous data layer to preload batches while other processing is\n    performed.\n    \"\"\"\n\n    def __init__(self, params, result):\n        self.result = result\n        self.batch_size = params['batch_size']\n        self.anno_list = params['anno_list']\n        self.im_shape = params['im_shape']\n        self.label_shortlist_path = params['label_shortlist']\n        self.num_labels = params.get('nlabels', NUM_LABELS)\n        self.memimages = bool(params.get('memimages', 0))\n        self.img_transform = params.get('img_transform', 'resize')\n        self.ynorm = bool(params.get('ynorm', 0))   # y := y / ||y||_1\n        self.wloss = bool(params.get('wloss', 0))\n        self.user_prefs = params.get('user_prefs', None)\n        self.scale_user_pref = bool(params.get('scale_user_pref', 0))\n\n        # Possible options:\n        # 'uniform' (Default) : Sample uniformly\n        # 'weighted': Sample a weight uniformly (usually between 1-5). Then sample an example from on of these.\n        self.sampling = params.get('sampling', 'uniform')\n\n        if self.label_shortlist_path is not None:\n            self.attr_id_to_idx = dict()\n            self.attr_id_to_weight = dict()\n            with open(self.label_shortlist_path, 'r') as f:\n                f.readline()   # Skip header line\n                for line in f:\n                    idx, attr_id, count, weight = line.strip().split('\\t')\n                    idx = int(idx)\n                    count = int(count)\n                    weight = float(weight)\n                    self.attr_id_to_idx[attr_id] = idx\n                    self.attr_id_to_weight[attr_id] = weight\n        else:\n            assert False, \"Not Supported\"\n            # self.attr_id_to_idx = load_attr_to_idx()\n\n        self.attr_id_list = self.attr_id_to_idx.keys()\n        self.n_attr = len(self.attr_id_list)\n\n        self.user_mat = None\n        if self.user_prefs is not None:\n            '''\n            This is a file of the format:\n            <attribute_id>  <attribute_name>    <score_1>   <score_2> .... <score_U>\n            where U = # of users\n            score_U indicates how important this attribute is to him/her\n            '''\n            with open(self.user_prefs) as uf:\n                uf.readline()   # Skip header line\n                pref_dct = dict()   # Store mapping: attr_id = [..., score_i, ...]\n                for line in uf:\n                    if line.strip() == '':\n                        continue\n                    tokens = line.strip().split('\\t')\n                    attr_id = tokens[0]\n                    attr_name = tokens[1]\n                    scores = [float(s) for s in tokens[2:]]\n                    if attr_id in self.attr_id_to_idx:\n                        pref_dct[attr_id] = scores\n\n                # Check n_users is consistent\n                n_users = len(pref_dct.values()[0])\n                assert all([n_users == len(x) for x in pref_dct.values()]), Counter([len(x) for x in pref_dct.values()])\n\n                # Manually fill-in safe\n                pref_dct[SAFE_ATTR_ID] = np.ones(n_users) * SAFE_WEIGHT\n                # Make sure we have preferences for all attributes that we need\n                assert all([pref_attr_id in self.attr_id_to_idx for pref_attr_id in pref_dct.keys()])\n\n                # Represent as a matrix: A x U\n                # Where col_j represents attribute preferences for user j\n                n_attr = len(self.attr_id_to_idx)\n                self.user_mat = np.zeros((n_attr, n_users))\n                for attr_id, idx in self.attr_id_to_idx.iteritems():\n                    attr_scores = pref_dct[attr_id]\n                    self.user_mat[idx] = attr_scores\n\n            print 'User preferences: '\n            print self.user_mat\n            print 'user_mat.shape = ', self.user_mat.shape\n\n            # Normalize user_mat\n            if self.scale_user_pref:\n                self.user_mat -= 2.5   # Assuming mean of scores = 2.5, so scale to [-2.5, 2.5]\n                self.user_mat /= 2.5   # Scale to [-1, 1]\n\n        # Store the list of annotation files as indexlist\n        self.indexlist = [line.rstrip('\\n') for line in open(self.anno_list)]\n\n        if self.memimages:\n            print \"Loading images into memory\"\n        print \"Loading {} annotations\".format(len(self.indexlist))\n\n        # Store each image-label object as a dict\n        # But, do not store the images. Only store the image file path\n        self.dictlist = [json.load(open(aidx)) for aidx in self.indexlist]\n        shuffle(self.dictlist)\n\n        # Create a weight vector\n        self.idx_to_attr_id = {v: k for k, v in self.attr_id_to_idx.iteritems()}\n        self.idx_to_weight = np.ones(68)\n        if self.wloss:\n            for idx in sorted(self.idx_to_attr_id.keys()):\n                attr_id = self.idx_to_attr_id[idx]\n                self.idx_to_weight[idx] = self.attr_id_to_weight[attr_id]\n\n        print 'Class weights: '\n        print self.idx_to_weight\n\n        if self.sampling == 'weighted':\n            '''\n            1. Create a mapping of WEIGHT (int) -> attribute_idx\n               weight of example = max(weight of attribute i in example)\n            2. When sampling next image:\n              a. Sample weight ~ [1, 2, 3, 4, 5]\n              b. Sample an example corresponding to this weight\n            Maintain a dict:\n                {\n                    1: [3, 10, 4, ...],\n                    2: [45, 11, 90, ...],\n                    ...\n                }\n            and pop an idx from the list when asked for next image\n            '''\n            self.weight_to_idx_list = get_w2idx(self.dictlist, self.attr_id_to_weight)\n            # Maintain a copy of this, because it will mutate in each iteration (pop() to consume)\n            self.org_weight_to_idx_list = copy.deepcopy(self.weight_to_idx_list)\n        elif self.sampling == 'class_weighted':\n            '''\n            1. Create a mapping of LABEL (attr_id) -> DICT_IDX\n            2. When sampling next image:\n              a. Sample class ~ [attr_1, attr_2, ..., attr_L]\n              b. Sample an example corresponding to this label\n            Maintain a dict:\n                {\n                    attr_1: [3, 10, 4, ...],\n                    attr_2: [45, 11, 90, ...],\n                    ...\n                }\n            and pop an idx from the list when asked for next image\n            '''\n            self.class_to_idx_list = get_class2idx(self.dictlist)\n            # Maintain a copy of this, because it will mutate in each iteration (pop() to consume)\n            self.org_class_to_idx_list = copy.deepcopy(self.class_to_idx_list)\n        else:\n            self._cur = 0  # current image\n            self.weight_to_idx_list = None\n            self.class_to_idx_list = None\n\n        # Add to each dict the label vector\n        for idx, this_anno in enumerate(self.dictlist):\n            # Prepare the multilabel\n            # Get the list of attributes this corresponds to\n            if 'labels' in this_anno:\n                attr_set = set(this_anno['labels'])\n            else:\n                this_attr_list = []\n                for categ_id, attr_id_list in this_anno['attributes'].iteritems():\n                    this_attr_list += attr_id_list\n                attr_set = set(this_attr_list)\n            multilabel = attribute_set_to_vec(self.attr_id_to_idx, attr_set, is_safe=this_anno['safe'])\n            if self.ynorm and np.sum(multilabel) > 0:\n                multilabel /= np.sum(multilabel)\n            assert np.sum(multilabel) > 0, 'Failed: np.sum(multilabel) > 0'\n            this_anno['label_vec'] = multilabel\n\n            image_path = this_anno['image_path']\n            image_resized_path = image_path.replace('/images_chunks/', '/images_chunks_resized/')\n            if os.path.exists(image_resized_path):\n                this_anno['image_path'] = image_resized_path\n\n            if self.memimages:\n                im = imread(this_anno['image_path'])\n                if len(im.shape) == 2:\n                    # This is a grayscale image\n                    im = np.asarray(Image.open(this_anno['image_path']).convert('RGB'))\n                elif len(im.shape) == 3 and im.shape[2] == 4:\n                    # CMYK Image\n                    im = np.asarray(Image.open(this_anno['image_path']).convert('RGB'))\n\n                if self.img_transform == 'resize':\n                    # Resize the image to the required shape\n                    im = scipy.misc.imresize(im, self.im_shape)\n\n                this_anno['im'] = im\n\n                if idx % 100 == 0:\n                    sys.stdout.write(\"processing %d/%d (%.2f%% done)   \\r\" % (idx, len(self.dictlist), idx * 100.0 / len(self.dictlist)))\n                    sys.stdout.flush()\n\n        print 'multilabel.shape = ', multilabel.shape\n        # this class does some simple data-manipulations\n        self.transformer = SimpleTransformer(mean=[104, 117, 123])\n\n        print \"BatchLoader initialized with {} images\".format(len(self.indexlist))\n\n    def get_weights(self):\n        return self.idx_to_weight\n\n    def get_user_prefs(self):\n        return self.user_mat.copy()\n\n    def get_attr_id_list(self):\n        return self.attr_id_list\n\n    def load_next_image(self):\n        \"\"\"\n        Load the next image in a batch.\n        \"\"\"\n\n        # Sample image -------------------------------------------------------------------------------------------------\n        # Choose which idx in dctlist to read\n        # The next block should fill this in\n        if self.sampling == 'weighted':\n            # 1. Sample a weight\n            this_w = np.random.choice(self.weight_to_idx_list.keys())\n            # 2.a. Is an image available for this weight. If not,\n            if len(self.weight_to_idx_list[this_w]) == 0:\n                # Copy from the original mapping\n                self.weight_to_idx_list = copy.deepcopy(self.org_weight_to_idx_list)\n                # Shuffle indices\n                for w in sorted(self.weight_to_idx_list.keys()):\n                    shuffle(self.weight_to_idx_list[w])\n            # 2.b. Get the next index\n            next_idx = self.weight_to_idx_list[this_w].pop()\n        elif self.sampling == 'class_weighted':\n            # 1. Sample a label\n            this_attr_id = np.random.choice(self.class_to_idx_list.keys())\n            # 2a. Is there a training example available for this weight? If not,\n            if len(self.class_to_idx_list[this_attr_id]) == 0:\n                # Copy from original mapping\n                self.class_to_idx_list = copy.deepcopy(self.org_class_to_idx_list)\n                # Shuffle them\n                for ai in self.class_to_idx_list:\n                    shuffle(self.class_to_idx_list[ai])\n            # 2b. Get next index\n            next_idx = self.class_to_idx_list[this_attr_id].pop()\n        else:\n            # Did we finish an epoch?\n            if self._cur == len(self.dictlist):\n                self._cur = 0\n                next_idx = self._cur\n                shuffle(self.dictlist)\n            else:\n                next_idx = self._cur\n                self._cur += 1\n\n        dct = self.dictlist[next_idx]  # Get the anno\n\n        # Load image ---------------------------------------------------------------------------------------------------\n        image_path = dct['image_path']\n\n        multilabel = dct['label_vec']\n        assert multilabel.shape[0] == self.num_labels, 'multilabel.shape[0] ({}) != self.num_labels ({})'.format(multilabel.shape[0], self.num_labels)\n\n        # Load an image\n        if 'im' in dct:\n            im = dct['im']\n        else:\n            im = imread(image_path)\n            if len(im.shape) == 2:\n                # This is a grayscale image\n                im = np.asarray(Image.open(image_path).convert('RGB'))\n            elif len(im.shape) == 3 and im.shape[2] == 4:\n                # CMYK Image\n                im = np.asarray(Image.open(image_path).convert('RGB'))\n        org_shape = im.shape\n\n        # Resize/Transform image ---------------------------------------------------------------------------------------\n        if self.img_transform == 'resize':\n            # Resize the image to the required shape\n            im = scipy.misc.imresize(im, self.im_shape)\n        elif self.img_transform == 'rand_crop':\n            # Take a random crop of size self.im_shape\n            # im.shape = [H, W, 3]\n            img_h, img_w, _ = im.shape\n            crop_h, crop_w = self.im_shape\n\n            # print 'Processing file: ', image_path\n            # print 'Old (w, h): ', (img_w, img_h)\n\n            if img_w < crop_w:\n                new_w = crop_w\n                new_h = int(np.round(img_h * (new_w / float(img_w))))   # Scale height to same aspect ratio\n                im = scipy.misc.imresize(im, (new_h, new_w))\n                img_w, img_h = new_w, new_h\n                # print 'New (w, h): ', (img_w, img_h)\n\n            if img_h < crop_h:\n                new_h = crop_h\n                new_w = int(np.round(img_w * (new_h / float(img_h))))\n                im = scipy.misc.imresize(im, (new_h, new_w))\n                img_w, img_h = new_w, new_h\n                # print 'New (w, h): ', (img_w, img_h)\n\n            # Sample (x1, y1) i.e, top-left point of the image\n            x1 = np.random.randint(low=0, high=(img_h - crop_h - 1))\n            y1 = np.random.randint(low=0, high=(img_w - crop_w - 1))\n            # Crop a window given this point\n            x2 = x1 + crop_h\n            y2 = y1 + crop_w\n            im = im[x1:x2, y1:y2, :]\n\n            # print '(x1, y1) = ', (x1, x2)\n            # print 'Cropped (w, h): ', (x2-x1, y2-y1)\n            # print 'im.shape = ', im.shape\n\n        # do a simple horizontal flip as data augmentation\n        flip = np.random.choice(2)*2-1\n        im = im[:, ::flip, :]\n\n        transformed_im = self.transformer.preprocess(im)\n\n        return transformed_im, multilabel\n\n\ndef check_params(params):\n    \"\"\"\n    A utility function to check the parameters for the data layers.\n    \"\"\"\n    # assert 'split' in params.keys(\n    # ), 'Params must include split (train, val, or test).'\n\n    required = ['batch_size', 'anno_list', 'im_shape']\n    for r in required:\n        assert r in params.keys(), 'Params must include {}'.format(r)\n\n\ndef print_info(name, params):\n    \"\"\"\n    Output some info regarding the class\n    \"\"\"\n    print \"{} initialized for split: {}, with bs: {}, im_shape: {}.\".format(\n        name,\n        params['anno_list'],\n        params['batch_size'],\n        params['im_shape'])","metadata":{"execution":{"iopub.status.busy":"2023-03-13T07:41:48.771017Z","iopub.status.idle":"2023-03-13T07:41:48.772877Z","shell.execute_reply.started":"2023-03-13T07:41:48.772501Z","shell.execute_reply":"2023-03-13T07:41:48.772538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}